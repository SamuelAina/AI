
```sql
DBCC SHRINKDATABASE (database_name, target_percent)
```
- `database_name`: The name of the database you want to shrink.
- `target_percent`: The desired free space as a percentage of the database size after the shrink operation. For example, `10` means 10% free space.

Example:
```sql
DBCC SHRINKDATABASE (MyDatabase, 10);
```

### 2. DBCC SHRINKFILE
This command shrinks the size of the specified data or log file for a database.

Syntax:
```sql
DBCC SHRINKFILE (file_name, target_size)
```
- `file_name`: The logical name of the file to shrink. You can get this name from the `sys.database_files` catalog view.
- `target_size`: The desired size of the file in megabytes. If `0` is specified, SQL Server will shrink the file to the smallest size possible.

Example:
```sql
DBCC SHRINKFILE (MyDataFile, 100);
```

### Considerations Before Shrinking
- **Shrinking a database should be done with caution** and typically only in specific scenarios, such as after archiving a significant amount of data. Regularly shrinking databases as part of routine maintenance is not recommended because it can cause fragmentation and degrade performance.
- After shrinking, **it's advisable to reorganize indexes** to mitigate the impact of fragmentation.

### Alternatives to Shrinking
- **Review data retention policies**: Instead of frequently shrinking files, consider if old or unnecessary data can be archived or purged, reducing the need for future shrinks.
- **Monitor file growth settings**: Ensure your database files are set to grow in a controlled manner that minimizes the need to release unused space frequently.

Shrinking operations can be resource-intensive and affect database performance. Therefore, they should ideally be performed during maintenance windows or periods of low activity.

#####################

To determine the free space in a SQL Server database, you can use several methods, including system stored procedures, system views, or SQL Server Management Studio (SSMS) reports. Below are some common approaches to find out the free space in both the data files and log files of your database:

### 1. Using the `sp_spaceused` Stored Procedure
This system stored procedure provides information about the total and unused space in the database.

```sql
EXEC sp_spaceused;
```
Running this command gives you an overview of the database size, unallocated space, and the size of the data and index information.

### 2. Using the `sys.database_files` System View
You can query this system view to get detailed information about the files in the database, including their size and available space.

```sql
SELECT 
    name AS FileName, 
    type_desc AS FileType,
    size/128.0 AS CurrentSizeMB, 
    size/128.0 - CAST(FILEPROPERTY(name, 'SpaceUsed') AS int)/128.0 AS FreeSpaceMB
FROM 
    sys.database_files;
```
This query shows the file name, type (ROWS for data and LOG for log files), current size in megabytes, and free space in megabytes for each file in the database.

### 3. Using the `sys.dm_db_file_space_usage` Dynamic Management View (DMV)
This DMV is useful for finding space usage information for tempdb specifically.

```sql
SELECT 
    name AS FileName, 
    type_desc AS FileType,
    size/128.0 AS CurrentSizeMB, 
    (size/128.0 - CAST(FILEPROPERTY(name, 'SpaceUsed') AS int)/128.0) AS FreeSpaceMB
FROM 
    tempdb.sys.database_files;
```
This query is specifically targeted at tempdb, but you can adapt it for other databases by changing the context using `USE [DatabaseName];` before running a similar query.

### 4. SQL Server Management Studio (SSMS) Reports
If you prefer a graphical interface, SSMS offers a range of reports that include disk usage by tables, databases, etc.

- Connect to your database instance in SSMS.
- Right-click on the database you want to inspect.
- Select **Reports** > **Standard Reports** > **Disk Usage**.

This report provides a visual representation of the disk space used by the database and includes details about the database size, unallocated space, and space used by data and log files.

These methods will help you understand the space utilization in your database, allowing for better database management and planning for future growth or maintenance activities.


########################
In SQL Server, determining whether a string is numeric can be approached in several ways, each with its own advantages and considerations. The method you choose may depend on the specific requirements of your query, such as the range of acceptable numeric formats (integers, decimals, scientific notation, etc.) and the version of SQL Server you are using. Here are some common methods:

### 1. `ISNUMERIC` Function

The `ISNUMERIC` function is the most straightforward way to check if a string is numeric. It returns `1` if the string can be converted to any numeric type and `0` otherwise.

```sql
SELECT CASE WHEN ISNUMERIC(yourColumn) = 1 THEN 'Numeric' ELSE 'Not Numeric' END AS CheckResult
FROM yourTable;
```

**Pros:**
- Simple and easy to use.

**Cons:**
- Can return `1` for strings that might not convert cleanly to a specific numeric type you're interested in (e.g., currency symbols, scientific notation).
- It considers some special characters like `+`, `-`, and `.` as numeric under certain conditions, which might not be desired.

### 2. `TRY_CAST`, `TRY_CONVERT`, and `TRY_PARSE`

Starting with SQL Server 2012, these functions attempt to convert a string to a specified data type, returning `NULL` if the conversion fails. For numeric checks, `TRY_CAST` and `TRY_CONVERT` are more precise than `ISNUMERIC`.

```sql
SELECT CASE WHEN TRY_CAST(yourColumn AS FLOAT) IS NOT NULL THEN 'Numeric' ELSE 'Not Numeric' END AS CheckResult
FROM yourTable;
```

Replace `FLOAT` with the specific numeric type you're interested in, if necessary.

**Pros:**
- More accurate than `ISNUMERIC` for checking if a string can be converted to a specific numeric type.
- `TRY_CONVERT` and `TRY_PARSE` allow for culture-specific formatting considerations (useful for decimals in different locales).

**Cons:**
- Not available in SQL Server versions before 2012.

### 3. `PATINDEX` and `LIKE`

For more specific numeric checks (e.g., integers only), you might resort to pattern matching, though it's more complex and less efficient.

```sql
SELECT CASE WHEN PATINDEX('%[^0-9]%', yourColumn) > 0 THEN 'Not Numeric' ELSE 'Numeric' END AS CheckResult
FROM yourTable;
```

Or using `LIKE` for simpler patterns:

```sql
SELECT CASE WHEN yourColumn NOT LIKE '%[^0-9]%' THEN 'Numeric' ELSE 'Not Numeric' END AS CheckResult
FROM yourTable;
```

**Pros:**
- Offers customizable pattern matching to fit specific numeric formats.
- Works on all SQL Server versions.

**Cons:**
- More complex and potentially less efficient.
- Not suitable for all numeric types without significant complexity.

### Conclusion

The "best" method depends on your specific needs:
- For a general numeric check, `ISNUMERIC` is easiest but least precise.
- For type-specific checks or SQL Server 2012 and later, `TRY_CAST`, `TRY_CONVERT`, and `TRY_PARSE` are preferable.
- For custom pattern checks or older SQL Server versions, `PATINDEX` or `LIKE` can be utilized, acknowledging their complexity and performance considerations.
################

If an app has the following fields in its database, describe the purpose of the App:

[Approval Type]
[Date of request]
[Business]
[Sub-business]
[Asset Class]
[Product]
[Product Description]
[Latest Update]
[Product Code in TP]
[Product Code in FPSL/GL]
[Booking Entity]
[GL Booking Unit]
[ESG related]
[If Yes ESG Provide description]
[Islamic Finance]
[If Yes Islamic Finance Provide description]
[Brief Description of the request]
[Has Business has sent a detailed request]
[If yes - Attach the email request]
[Booking system]
[Accounting Treatment]
[Approved with limitations]
[If Yes, what is the tactical solution]
[If Yes, what is the strategic solution]
[Yes, who is the owner]
[Follow up actions (Caveats)]
[Approval email sent to business]
[TP system source file name which sends data to CDW/CCL for PPG ident? (y/n)]
[For above please provide comments]
[Local Product code (TP System) to Standard Product code (BCRS) mapped? (y/n)]
[For above please provide comments..:]
[Trade processed from CDW to BCRS?]
[For above please provide comments..`]
[What is rejection code/Reason for the trades rejected in ET Layer?]
[For above please provide comments.::]
[EAD methodology/formula for the product identified?]
[For above please provide comments.:`]
[Product code mapped to correct Asset class for SACCR for EAD computation?]
[For above please provide comments.`:]
[Relevant data fields available for computing EAD for the product? (yes/no)]
[For above please provide comments.``]
[Post execution checks required e.g. check first trade executed by desk? (y/n)]
[For above please provide comments:]
[CRR Articles related to the product identified?]
[For above please provide comments:.:]
[Product reported correctly under Credit Risk reporting (C7 & C8) report?]
[For above please provide comments:.`]
[Product correctly calculated under Large Exposure (LE) reporting?]
[For above please provide comments::]
[Product reported correctly under for Leverage (LVR) Reporting (LR Calc rpt)?]
[For above please provide comments:`]
[Product correctly reported under for Capital Reporting (CA2 Return)?]
[For above please provide comments```]
[Results of test sample aligned to expected treatment for Reg treatment?]
[For above please provide comments:``]
[Future regulation to be covered as a part of the PPG?]
[For above please provide comments`.:]
[Manual intervention - Any process change (Y/N)]
[For above please provide comments`.`]
[Manual work has a remediation plan (Y/N)]
[For above please provide comments`:]
[Target date of remediation]
[Remediated by]
[Remediation plan and Target date (discussion email)]
[PIR Observations]
[Follow up actions]
[Target date for closure]
[Engagement with Change team required to understand dataflows?]
[For above please provide comments`::]
[Engagement with Change team required to understand Capital computation?]
[For above please provide comments`:`]
[Any manual intervention required to compute RWA/LE/Leverage?]
[For above please provide comments``]
[Product to be included in Unders/Overs list for PRA Reporting?]
[For above please provide comments``:]
[Expected manual adjustment been discussed in PPG forum with GRR?]
[Name of the Preparer]
[GFS Reviewer]
[GCRR Reviewer]
[GFS Approver]
[GCRR Approver]
[Approval Status]
[Approver Date]
[Approver comments]
[Is the data feeding strategically for liquidity and IRRBB reporting?.]
[If not, what is the manual process required.]
[If Yes, which field is impacted.]
[Is the amount below threshold for manual adjustments.]
[Has the PPG been added to the monitoring list?.]
[Review and Analysis Attachment.]
[Summary of treatment in LCR, CFMR, NSFR and SH.]
[LCR Report Template section.]
[LCR Report Template - Specific line if applicable.]
[CFMR Report Template section.]
[CFMR Report Template - Specific line if applicable.]
[NSFR Report Template section.]
[NSFR Report Template - Specific line if applicable.]
[Regulatory Reporting Attachment.]
[Trading Book / Banking Book.]
[IRRBB Treatment (should we include LCR/CFMR/NSFR also).]
[IRRBB Attachment.]
[Manual work has a remediation plan (Y/N).]
[For above please provide comments.]
[Has the manual work has a remediation plan (description).]
[Target date of remediation.]
[Remediated by.]
[Remediation plan and Target date (discussion email).]
[Engagement with Change team required to understand dataflows?.]
[For above please provide comments..]
[Engagement with Change Attachment.]
[PIR Observations.]
[Target date for closure.]
[PIR required Attachment.]
[Name of the Preparer.]
[GFS Reviewer.]
[GLRR Reviewer.]
[GFS Approver.]
[GLRR Approver.]
[Approval Status.]
[Approver Date.]
[Approver comments.]


Based on the extensive list of fields in its database, this application appears to serve a comprehensive role in the financial regulatory and compliance domain, specifically tailored for banking and finance institutions. The purpose of the app can be summarized as follows:

### Product and Service Approval and Compliance Management

- **Approval and Request Tracking**: Fields like [Approval Type], [Date of request], and [Approval Status] indicate the app manages the approval process for various financial products and services, tracking them from request to approval.
  
- **Business and Product Categorization**: With fields specifying [Business], [Sub-business], [Asset Class], [Product], and [Product Description], the app categorizes products and services, likely to ensure they align with specific regulatory requirements or internal categorizations.

### Risk and Regulatory Reporting

- **Risk and Compliance Reporting**: Fields related to ESG (Environmental, Social, and Governance), Islamic Finance, Accounting Treatment, and specific regulatory reporting (e.g., [Product reported correctly under Credit Risk reporting]) suggest the app plays a critical role in ensuring financial products comply with varied regulatory and risk management requirements.

- **Regulatory Data Management**: The presence of fields like [Product Code in TP], [Product Code in FPSL/GL], and specific questions about data mappings ([Local Product code (TP System) to Standard Product code (BCRS) mapped?]) indicate the app's role in managing and reconciling data across different systems for regulatory purposes.

### Monitoring and Remediation

- **Compliance Monitoring and Follow-Up**: Fields such as [Follow up actions], [Manual intervention], [Remediation plan and Target date], and [Engagement with Change team required] suggest the app not only identifies compliance issues but also facilitates the tracking of remediation efforts and engagements with teams for resolution.

- **Manual Adjustments and Regulatory Considerations**: The app addresses manual adjustments and interventions ([Expected manual adjustment been discussed in PPG forum with GRR?]), showing its use in scenarios where automated processes are insufficient, and manual oversight is required.

### Reporting and Documentation

- **Detailed Reporting and Documentation**: With numerous fields requesting comments, descriptions, and attachment of relevant documents (e.g., [Review and Analysis Attachment], [Regulatory Reporting Attachment]), the app likely serves as a central repository for documentation related to product approvals, risk assessments, and regulatory compliance efforts.


A very big learning process in which the learning is still ongoing.
We may have set out with very lofty dreams and visions, the path to which would inevitably be rough and turturous. There have been succeses and there have been lessons. One of the main successes is the validation of the tenacity and transparency. Whatever steps we next take, we must build on what we have learnt and consolidate on the streght that we have gained. There are new realities emerging in Africa, some of which we can key into to materialize our dreams and vision. We should not certainly give up. Just step back and radically re-imagine.
- **Regulatory Framework Alignment**: Fields specifically mentioning regulatory frameworks and reporting requirements ([LCR Report Template section], [CFMR Report Template section], [IRRBB Treatment]) indicate the app's alignment with specific regulatory frameworks, facilitating compliance with liquidity, market, and operational risk requirements.

In summary, this app seems to be a complex, multi-functional platform designed to manage, track, and report on the compliance and approval processes for financial products and services, ensuring alignment with internal policies and external regulatory requirements. It likely serves users in risk management, compliance, and product management roles within financial institutions.
+++++++++++


// Function to open a connection to the IndexedDB database and add data
function storeDataInIndexedDB(dbName, storeName, data) {
    // Open a connection to the database
    const request = indexedDB.open(dbName, 1);

    // Handle the event for upgrading needed to create the object store
    request.onupgradeneeded = function(event) {
        const db = event.target.result;
        // Create an object store with a given name and keyPath
        db.createObjectStore(storeName, { keyPath: "id" });
    };

    // Handle successful database opening
    request.onsuccess = function(event) {
        const db = event.target.result;
        // Create a transaction to write data
        const transaction = db.transaction(storeName, "readwrite");
        // Get the object store
        const store = transaction.objectStore(storeName);
        // Add data to the store
        data.forEach(item => store.add(item));
        // Complete the transaction
        transaction.oncomplete = function() {
            console.log("All data has been added to the database successfully!");
        };
    };

    // Handle errors during the database request
    request.onerror = function(event) {
        console.error('Database error:', event.target.error);
    };
}

// Example usage
const data = [
    { id: 1, name: "John Doe", email: "john@example.com" },
    { id: 2, name: "Jane Doe", email: "jane@example.com" }
];
storeDataInIndexedDB("myDatabase", "myStore", data);
